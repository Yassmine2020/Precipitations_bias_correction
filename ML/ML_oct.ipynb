{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DataScience\\AppData\\Local\\Temp\\ipykernel_7980\\2923882287.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "oct_merged = pd.read_csv('../DATASET/obs_est_merged/oct_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>precip_est</th>\n",
       "      <th>precip_obs</th>\n",
       "      <th>bias_oct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>1981</td>\n",
       "      <td>11</td>\n",
       "      <td>136.470150</td>\n",
       "      <td>150.665280</td>\n",
       "      <td>-14.195130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>1981</td>\n",
       "      <td>11</td>\n",
       "      <td>132.524840</td>\n",
       "      <td>139.511110</td>\n",
       "      <td>-6.986270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>1981</td>\n",
       "      <td>11</td>\n",
       "      <td>128.341250</td>\n",
       "      <td>122.909546</td>\n",
       "      <td>5.431704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>1981</td>\n",
       "      <td>11</td>\n",
       "      <td>122.454530</td>\n",
       "      <td>117.767334</td>\n",
       "      <td>4.687196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>1981</td>\n",
       "      <td>11</td>\n",
       "      <td>120.415470</td>\n",
       "      <td>122.222900</td>\n",
       "      <td>-1.807430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230251</th>\n",
       "      <td>20.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>0.039531</td>\n",
       "      <td>0.114441</td>\n",
       "      <td>-0.074910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230252</th>\n",
       "      <td>20.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>0.039531</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230253</th>\n",
       "      <td>20.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>0.074687</td>\n",
       "      <td>0.057220</td>\n",
       "      <td>0.017467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230254</th>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>0.082500</td>\n",
       "      <td>0.171661</td>\n",
       "      <td>-0.089162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230255</th>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>0.027812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>230256 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         lat   lon  year  month  precip_est  precip_obs   bias_oct\n",
       "0       45.0 -20.0  1981     11  136.470150  150.665280 -14.195130\n",
       "1       45.0 -19.0  1981     11  132.524840  139.511110  -6.986270\n",
       "2       45.0 -18.0  1981     11  128.341250  122.909546   5.431704\n",
       "3       45.0 -17.0  1981     11  122.454530  117.767334   4.687196\n",
       "4       45.0 -16.0  1981     11  120.415470  122.222900  -1.807430\n",
       "...      ...   ...   ...    ...         ...         ...        ...\n",
       "230251  20.0  16.0  2017      4    0.039531    0.114441  -0.074910\n",
       "230252  20.0  17.0  2017      4    0.039531    0.000000   0.039531\n",
       "230253  20.0  18.0  2017      4    0.074687    0.057220   0.017467\n",
       "230254  20.0  19.0  2017      4    0.082500    0.171661  -0.089162\n",
       "230255  20.0  20.0  2017      4    0.027812    0.000000   0.027812\n",
       "\n",
       "[230256 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oct_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "oct_average= oct_merged\n",
    "oct_average = oct_average.drop(columns=['precip_obs'])\n",
    "oct_average = oct_average[(oct_average['lon'] >= -18) & (oct_average['lon'] <= 0)]\n",
    "oct_average = oct_average[(oct_average['lat'] >= 20) & (oct_average['lat'] <= 38)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>precip_est</th>\n",
       "      <th>bias_oct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>38.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>1981</td>\n",
       "      <td>11</td>\n",
       "      <td>64.224060</td>\n",
       "      <td>-22.354310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>37.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>1981</td>\n",
       "      <td>11</td>\n",
       "      <td>60.282658</td>\n",
       "      <td>-19.825982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>36.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>1981</td>\n",
       "      <td>11</td>\n",
       "      <td>54.298283</td>\n",
       "      <td>0.968815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>35.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>1981</td>\n",
       "      <td>11</td>\n",
       "      <td>49.118595</td>\n",
       "      <td>21.530705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>34.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>1981</td>\n",
       "      <td>11</td>\n",
       "      <td>44.833440</td>\n",
       "      <td>18.908757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230053</th>\n",
       "      <td>24.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>4.547344</td>\n",
       "      <td>3.860698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230094</th>\n",
       "      <td>23.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>3.219219</td>\n",
       "      <td>3.047557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230135</th>\n",
       "      <td>22.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>1.488750</td>\n",
       "      <td>0.973766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230176</th>\n",
       "      <td>21.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>1.211406</td>\n",
       "      <td>1.039745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230217</th>\n",
       "      <td>20.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>0.941875</td>\n",
       "      <td>0.770213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4104 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         lat   lon  year  month  precip_est   bias_oct\n",
       "289     38.0 -18.0  1981     11   64.224060 -22.354310\n",
       "330     37.0 -18.0  1981     11   60.282658 -19.825982\n",
       "371     36.0 -18.0  1981     11   54.298283   0.968815\n",
       "412     35.0 -18.0  1981     11   49.118595  21.530705\n",
       "453     34.0 -18.0  1981     11   44.833440  18.908757\n",
       "...      ...   ...   ...    ...         ...        ...\n",
       "230053  24.0 -18.0  2017      4    4.547344   3.860698\n",
       "230094  23.0 -18.0  2017      4    3.219219   3.047557\n",
       "230135  22.0 -18.0  2017      4    1.488750   0.973766\n",
       "230176  21.0 -18.0  2017      4    1.211406   1.039745\n",
       "230217  20.0 -18.0  2017      4    0.941875   0.770213\n",
       "\n",
       "[4104 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oct_average[oct_average['lon'] == -18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>precip_est</th>\n",
       "      <th>bias_oct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>38.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>1981</td>\n",
       "      <td>11</td>\n",
       "      <td>64.224060</td>\n",
       "      <td>-22.354310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>38.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>1981</td>\n",
       "      <td>11</td>\n",
       "      <td>59.290470</td>\n",
       "      <td>-34.947810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>38.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>1981</td>\n",
       "      <td>11</td>\n",
       "      <td>55.923283</td>\n",
       "      <td>-31.967342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>38.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>1981</td>\n",
       "      <td>11</td>\n",
       "      <td>52.946720</td>\n",
       "      <td>-37.812560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>38.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>1981</td>\n",
       "      <td>11</td>\n",
       "      <td>48.997500</td>\n",
       "      <td>-51.481626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230231</th>\n",
       "      <td>20.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>0.391094</td>\n",
       "      <td>-0.524434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230232</th>\n",
       "      <td>20.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>0.723125</td>\n",
       "      <td>-0.879048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230233</th>\n",
       "      <td>20.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>0.824687</td>\n",
       "      <td>-1.292470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230234</th>\n",
       "      <td>20.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>0.445781</td>\n",
       "      <td>-2.873006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230235</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>0.152812</td>\n",
       "      <td>-1.964345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77976 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         lat   lon  year  month  precip_est   bias_oct\n",
       "289     38.0 -18.0  1981     11   64.224060 -22.354310\n",
       "290     38.0 -17.0  1981     11   59.290470 -34.947810\n",
       "291     38.0 -16.0  1981     11   55.923283 -31.967342\n",
       "292     38.0 -15.0  1981     11   52.946720 -37.812560\n",
       "293     38.0 -14.0  1981     11   48.997500 -51.481626\n",
       "...      ...   ...   ...    ...         ...        ...\n",
       "230231  20.0  -4.0  2017      4    0.391094  -0.524434\n",
       "230232  20.0  -3.0  2017      4    0.723125  -0.879048\n",
       "230233  20.0  -2.0  2017      4    0.824687  -1.292470\n",
       "230234  20.0  -1.0  2017      4    0.445781  -2.873006\n",
       "230235  20.0   0.0  2017      4    0.152812  -1.964345\n",
       "\n",
       "[77976 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oct_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>precip_est</th>\n",
       "      <th>bias_oct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>77976.000000</td>\n",
       "      <td>77976.000000</td>\n",
       "      <td>77976.000000</td>\n",
       "      <td>77976.000000</td>\n",
       "      <td>77976.000000</td>\n",
       "      <td>77976.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>1999.166667</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>21.826232</td>\n",
       "      <td>2.987794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.477261</td>\n",
       "      <td>5.477261</td>\n",
       "      <td>10.399052</td>\n",
       "      <td>4.349357</td>\n",
       "      <td>24.393391</td>\n",
       "      <td>26.384423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>-18.000000</td>\n",
       "      <td>1981.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.004160</td>\n",
       "      <td>-630.773292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>-14.000000</td>\n",
       "      <td>1990.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.867173</td>\n",
       "      <td>-0.460557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>1999.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>8.974951</td>\n",
       "      <td>1.854420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>39.474083</td>\n",
       "      <td>11.414042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>131.355040</td>\n",
       "      <td>109.941878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                lat           lon          year         month    precip_est  \\\n",
       "count  77976.000000  77976.000000  77976.000000  77976.000000  77976.000000   \n",
       "mean      29.000000     -9.000000   1999.166667      5.500000     21.826232   \n",
       "std        5.477261      5.477261     10.399052      4.349357     24.393391   \n",
       "min       20.000000    -18.000000   1981.000000      1.000000     -0.004160   \n",
       "25%       24.000000    -14.000000   1990.000000      2.000000      1.867173   \n",
       "50%       29.000000     -9.000000   1999.000000      3.500000      8.974951   \n",
       "75%       34.000000     -4.000000   2008.000000     11.000000     39.474083   \n",
       "max       38.000000      0.000000   2017.000000     12.000000    131.355040   \n",
       "\n",
       "           bias_oct  \n",
       "count  77976.000000  \n",
       "mean       2.987794  \n",
       "std       26.384423  \n",
       "min     -630.773292  \n",
       "25%       -0.460557  \n",
       "50%        1.854420  \n",
       "75%       11.414042  \n",
       "max      109.941878  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oct_average.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "oct_ndup = oct_average.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77976"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(oct_average.duplicated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "oct_test = oct_average.sort_values(['year', 'month'])\n",
    "oct_test = oct_average.reset_index(drop=True)\n",
    "\n",
    "X, y = oct_test[['lat', 'lon', 'month', 'precip_est', 'year']], oct_test['bias_oct'] \n",
    "# X = X.sort_values('month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>precip_est</th>\n",
       "      <th>bias_oct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>1981</td>\n",
       "      <td>11</td>\n",
       "      <td>64.224060</td>\n",
       "      <td>-22.354310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>1981</td>\n",
       "      <td>11</td>\n",
       "      <td>59.290470</td>\n",
       "      <td>-34.947810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>1981</td>\n",
       "      <td>11</td>\n",
       "      <td>55.923283</td>\n",
       "      <td>-31.967342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>1981</td>\n",
       "      <td>11</td>\n",
       "      <td>52.946720</td>\n",
       "      <td>-37.812560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>1981</td>\n",
       "      <td>11</td>\n",
       "      <td>48.997500</td>\n",
       "      <td>-51.481626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77971</th>\n",
       "      <td>20.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>0.391094</td>\n",
       "      <td>-0.524434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77972</th>\n",
       "      <td>20.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>0.723125</td>\n",
       "      <td>-0.879048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77973</th>\n",
       "      <td>20.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>0.824687</td>\n",
       "      <td>-1.292470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77974</th>\n",
       "      <td>20.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>0.445781</td>\n",
       "      <td>-2.873006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77975</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>0.152812</td>\n",
       "      <td>-1.964345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77976 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lat   lon  year  month  precip_est   bias_oct\n",
       "0      38.0 -18.0  1981     11   64.224060 -22.354310\n",
       "1      38.0 -17.0  1981     11   59.290470 -34.947810\n",
       "2      38.0 -16.0  1981     11   55.923283 -31.967342\n",
       "3      38.0 -15.0  1981     11   52.946720 -37.812560\n",
       "4      38.0 -14.0  1981     11   48.997500 -51.481626\n",
       "...     ...   ...   ...    ...         ...        ...\n",
       "77971  20.0  -4.0  2017      4    0.391094  -0.524434\n",
       "77972  20.0  -3.0  2017      4    0.723125  -0.879048\n",
       "77973  20.0  -2.0  2017      4    0.824687  -1.292470\n",
       "77974  20.0  -1.0  2017      4    0.445781  -2.873006\n",
       "77975  20.0   0.0  2017      4    0.152812  -1.964345\n",
       "\n",
       "[77976 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oct_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>P-Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lat</td>\n",
       "      <td>-1.334424</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lon</td>\n",
       "      <td>0.020432</td>\n",
       "      <td>3.122837e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>month</td>\n",
       "      <td>-0.721398</td>\n",
       "      <td>1.183377e-208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>precip_est</td>\n",
       "      <td>0.492407</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>year</td>\n",
       "      <td>0.047894</td>\n",
       "      <td>8.869667e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Feature  Coefficient        P-Value\n",
       "1         lat    -1.334424   0.000000e+00\n",
       "2         lon     0.020432   3.122837e-01\n",
       "3       month    -0.721398  1.183377e-208\n",
       "4  precip_est     0.492407   0.000000e+00\n",
       "5        year     0.047894   8.869667e-07"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Adding a constant to the model (statsmodels does not add a constant by default)\n",
    "X_train_sm = sm.add_constant(X_train)\n",
    "\n",
    "# Fit the Ordinary Least Squares model with statsmodels\n",
    "model = sm.OLS(y_train, X_train_sm)\n",
    "results = model.fit()\n",
    "\n",
    "# Get coefficients and p-values\n",
    "coefficients = results.params\n",
    "p_values = results.pvalues\n",
    "\n",
    "# Create a DataFrame for easier visualization\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': coefficients.index,\n",
    "    'Coefficient': coefficients.values,\n",
    "    'P-Value': p_values.values\n",
    "})\n",
    "\n",
    "# Filtering to remove the constant (intercept) term if present\n",
    "feature_importance = feature_importance[feature_importance['Feature'] != 'const']\n",
    "\n",
    "display(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sorting the features by the absolute value of their coefficients, considering only significant ones (p < 0.05)\n",
    "significant_features = feature_importance[feature_importance['P-Value'] < 0.05]\n",
    "significant_features = significant_features.sort_values(by='Coefficient', key=abs, ascending=False)\n",
    "\n",
    "# Plotting feature importance for significant features\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(significant_features['Feature'],  abs(significant_features['Coefficient']), color='b')\n",
    "plt.title('Feature Importance in Linear Regression (Significant Features)')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Coefficient Value')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train Linear Regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Get coefficients\n",
    "coefficients = model.coef_\n",
    "\n",
    "# Create a DataFrame for easier visualization\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': coefficients\n",
    "})\n",
    "\n",
    "# Sorting the features by the absolute value of their coefficients\n",
    "feature_importance = feature_importance.sort_values(by='Coefficient', key=abs, ascending=False)\n",
    "\n",
    "# Plotting feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(feature_importance['Feature'], feature_importance['Coefficient'], color='b')\n",
    "plt.title('Feature Importance in Linear Regression')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Coefficient Value')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the models\n",
    "# models = {\n",
    "#     \"Linear Regression\": LinearRegression(),\n",
    "#     \"XGBoost\": XGBRegressor(random_state=42),\n",
    "#     \"Random Forest\": RandomForestRegressor(random_state=42),\n",
    "#     \"ExtraTrees Regressor\": ExtraTreesRegressor(random_state=42),\n",
    "#     \"LGBM Regressor\": LGBMRegressor(random_state=42)\n",
    "# }\n",
    "# k = 4\n",
    "# kf = KFold(n_splits=k)\n",
    "# results = {}\n",
    "\n",
    "# for model_name, model in models.items():\n",
    "#     train_rmse_scores = []\n",
    "#     test_rmse_scores = []\n",
    "#     train_r2_scores = []\n",
    "#     test_r2_scores = []\n",
    "\n",
    "#     # Note that we pass groups to the split method\n",
    "#     for train_index, test_index in kf.split(X):\n",
    "#         x_train_fold, x_test_fold = X.iloc[train_index].drop('year'), X.iloc[test_index].drop('year')\n",
    "\n",
    "#         print(f'''▶️ X_train{x_train_fold['month'].unique()}\n",
    "# ▶️ X_test{x_test_fold['month'].unique()}''')\n",
    "#         print(\"Train indices:\", train_index, \"Test indices:\", test_index)\n",
    "\n",
    "#         y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "#         # Train and predict\n",
    "#         model.fit(x_train_fold, y_train_fold)\n",
    "#         y_pred_train = model.predict(x_train_fold)\n",
    "#         y_pred_test = model.predict(x_test_fold)\n",
    "\n",
    "#         # Calculate RMSE\n",
    "#         rmse_train = mean_squared_error(y_train_fold, y_pred_train, squared=False)\n",
    "#         rmse_test = mean_squared_error(y_test_fold, y_pred_test, squared=False)\n",
    "#         r2_train = r2_score(y_train_fold, y_pred_train)\n",
    "#         r2_test = r2_score(y_test_fold, y_pred_test)\n",
    "\n",
    "#         train_rmse_scores.append(rmse_train)\n",
    "#         test_rmse_scores.append(rmse_test)\n",
    "#         train_r2_scores.append(r2_train)\n",
    "#         test_r2_scores.append(r2_test)\n",
    "\n",
    "#     avg_train_rmse = sum(train_rmse_scores) / k\n",
    "#     avg_test_rmse = sum(test_rmse_scores) / k\n",
    "#     avg_train_r2 = sum(train_r2_scores) / k\n",
    "#     avg_test_r2 = sum(test_r2_scores) / k\n",
    "\n",
    "#     results[model_name] = {\n",
    "#         \"train_rmse\": avg_train_rmse,\n",
    "#         \"test_rmse\": avg_test_rmse,\n",
    "#         \"train_r2\": avg_train_r2,\n",
    "#         \"test_r2\": avg_test_r2\n",
    "#     }\n",
    "\n",
    "# # for model_name, metrics in results.items():\n",
    "# #     print(f\"{model_name} - Train RMSE: {metrics['train_rmse']}, Test RMSE: {metrics['test_rmse']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000175 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 294\n",
      "[LightGBM] [Info] Number of data points in the train set: 12996, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 3.691295\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000231 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 294\n",
      "[LightGBM] [Info] Number of data points in the train set: 25992, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 2.897007\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000334 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 294\n",
      "[LightGBM] [Info] Number of data points in the train set: 38988, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 2.842882\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000518 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 294\n",
      "[LightGBM] [Info] Number of data points in the train set: 51984, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 2.818495\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001658 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 294\n",
      "[LightGBM] [Info] Number of data points in the train set: 64980, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 2.174429\n"
     ]
    }
   ],
   "source": [
    "# Define the models\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"XGBoost\": XGBRegressor(random_state=42),\n",
    "    \"Random Forest\": RandomForestRegressor(random_state=42),\n",
    "    \"ExtraTrees Regressor\": ExtraTreesRegressor(random_state=42),\n",
    "    \"LGBM Regressor\": LGBMRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "k = 5 # 80% 20%\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    train_rmse_scores = []\n",
    "    test_rmse_scores = []\n",
    "    train_r2_scores = []\n",
    "    test_r2_scores = []\n",
    "\n",
    "    # Note that we pass groups to the split method\n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        x_train_fold, x_test_fold = X.iloc[train_index].drop(columns=['year', 'month']), X.iloc[test_index].drop(columns=['year', 'month'])\n",
    "        # x_train_fold, x_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
    "\n",
    "\n",
    "#         print(f'''▶️ X_train{x_train_fold['year'].unique()}\n",
    "# ▶️ X_test{x_test_fold['year'].unique()}''')\n",
    "        # print(\"Train indices:\", train_index, \"Test indices:\", test_index)\n",
    "\n",
    "        y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # Train and predict\n",
    "        model.fit(x_train_fold, y_train_fold)\n",
    "        y_pred_train = model.predict(x_train_fold)\n",
    "        y_pred_test = model.predict(x_test_fold)\n",
    "\n",
    "        # Calculate RMSE\n",
    "        rmse_train = mean_squared_error(y_train_fold, y_pred_train, squared=False)\n",
    "        rmse_test = mean_squared_error(y_test_fold, y_pred_test, squared=False)\n",
    "        r2_train = r2_score(y_train_fold, y_pred_train)\n",
    "        r2_test = r2_score(y_test_fold, y_pred_test)\n",
    "\n",
    "        train_rmse_scores.append(rmse_train)\n",
    "        test_rmse_scores.append(rmse_test)\n",
    "        train_r2_scores.append(r2_train)\n",
    "        test_r2_scores.append(r2_test)\n",
    "\n",
    "    avg_train_rmse = sum(train_rmse_scores) / k\n",
    "    avg_test_rmse = sum(test_rmse_scores) / k\n",
    "    avg_train_r2 = sum(train_r2_scores) / k\n",
    "    avg_test_r2 = sum(test_r2_scores) / k\n",
    "\n",
    "    results[model_name] = {\n",
    "        \"train_rmse\": avg_train_rmse,\n",
    "        \"test_rmse\": avg_test_rmse,\n",
    "        \"train_r2\": avg_train_r2,\n",
    "        \"test_r2\": avg_test_r2\n",
    "    }\n",
    "\n",
    "# for model_name, metrics in results.items():\n",
    "#     print(f\"{model_name} - Train RMSE: {metrics['train_rmse']}, Test RMSE: {metrics['test_rmse']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import plotly.io as pio\n",
    "\n",
    "data = results\n",
    "models = list(data.keys())\n",
    "train_rmse = [data[model]['train_rmse'] for model in models]\n",
    "test_rmse = [data[model]['test_rmse'] for model in models]\n",
    "train_r2 = [data[model]['train_r2'] for model in models]\n",
    "test_r2 = [data[model]['test_r2'] for model in models]\n",
    "\n",
    "train_rmse = [round(num, 2) for num in train_rmse]\n",
    "test_rmse = [round(num, 2) for num in test_rmse]\n",
    "train_r2 = [round(num, 2) for num in train_r2]\n",
    "test_r2 = [round(num, 2) for num in test_r2]\n",
    "\n",
    "standard_deviation = np.std(y)  # Calculate standard deviation using numpy\n",
    "sample_size = len(y)  # Calculate sample size\n",
    "\n",
    "standard_error = standard_deviation / np.sqrt(sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": "blue"
         },
         "name": "Train R²",
         "text": [
          "0.08",
          "0.36",
          "0.86",
          "1.0",
          "0.25"
         ],
         "textposition": "auto",
         "type": "bar",
         "x": [
          "Linear Regression",
          "XGBoost",
          "Random Forest",
          "ExtraTrees Regressor",
          "LGBM Regressor"
         ],
         "y": [
          0.08,
          0.36,
          0.86,
          1,
          0.25
         ]
        },
        {
         "marker": {
          "color": "red"
         },
         "name": "Test R²",
         "text": [
          "0.07",
          "0.07",
          "-0.08",
          "-0.33",
          "0.12"
         ],
         "textposition": "auto",
         "type": "bar",
         "x": [
          "Linear Regression",
          "XGBoost",
          "Random Forest",
          "ExtraTrees Regressor",
          "LGBM Regressor"
         ],
         "y": [
          0.07,
          0.07,
          -0.08,
          -0.33,
          0.12
         ]
        }
       ],
       "layout": {
        "barmode": "group",
        "legend": {
         "title": {
          "text": "Data"
         }
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "R²"
        },
        "width": 600,
        "xaxis": {
         "title": {
          "text": "Models"
         }
        },
        "yaxis": {
         "title": {
          "text": "Value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "# Bar chart for R²\n",
    "fig.add_trace(go.Bar(\n",
    "    x=models,\n",
    "    y=train_r2,\n",
    "    name='Train R²',\n",
    "    marker_color='blue',\n",
    "    text=train_r2,  # Add this line to specify the text for each bar\n",
    "    # 'auto' places the text inside the bars; you can also use 'outside' or 'inside'\n",
    "    textposition='auto'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=models,\n",
    "    y=test_r2,\n",
    "    name='Test R²',\n",
    "    marker_color='red',\n",
    "    text=test_r2,  # Add this line to specify the text for each bar\n",
    "    # 'auto' places the text inside the bars; you can also use 'outside' or 'inside'\n",
    "    textposition='auto'\n",
    "))\n",
    "\n",
    "# Update the layout\n",
    "fig.update_layout(\n",
    "    barmode='group',\n",
    "    title='R²',\n",
    "    xaxis_title='Models',\n",
    "    yaxis_title='Value',\n",
    "    legend_title='Data',\n",
    "    width=600,\n",
    "    # plot_bgcolor='rgba(0,0,0,0)',  # Set plot background color to transparent\n",
    "    # paper_bgcolor='rgba(0,0,0,0)'\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": "blue"
         },
         "name": "Train RMSE",
         "text": [
          "24.98",
          "20.87",
          "9.76",
          "0.0",
          "22.57"
         ],
         "textposition": "auto",
         "type": "bar",
         "x": [
          "Linear Regression",
          "XGBoost",
          "Random Forest",
          "ExtraTrees Regressor",
          "LGBM Regressor"
         ],
         "y": [
          24.98,
          20.87,
          9.76,
          0,
          22.57
         ]
        },
        {
         "marker": {
          "color": "red"
         },
         "name": "Test RMSE",
         "text": [
          "25.66",
          "25.6",
          "27.42",
          "30.14",
          "24.89"
         ],
         "textposition": "auto",
         "type": "bar",
         "x": [
          "Linear Regression",
          "XGBoost",
          "Random Forest",
          "ExtraTrees Regressor",
          "LGBM Regressor"
         ],
         "y": [
          25.66,
          25.6,
          27.42,
          30.14,
          24.89
         ]
        },
        {
         "line": {
          "color": "orange",
          "width": 2
         },
         "mode": "lines+markers",
         "name": "Std",
         "type": "scatter",
         "x": [
          "Linear Regression",
          "XGBoost",
          "Random Forest",
          "ExtraTrees Regressor",
          "LGBM Regressor"
         ],
         "y": [
          26.384253318415613,
          26.384253318415613,
          26.384253318415613,
          26.384253318415613,
          26.384253318415613
         ]
        }
       ],
       "layout": {
        "barmode": "group",
        "legend": {
         "title": {
          "text": "Data"
         }
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "RMSE"
        },
        "width": 600,
        "xaxis": {
         "title": {
          "text": "Models"
         }
        },
        "yaxis": {
         "title": {
          "text": "Value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "# Bar chart for RMSE\n",
    "fig.add_trace(go.Bar(\n",
    "    x=models,\n",
    "    y=train_rmse,\n",
    "    name='Train RMSE',\n",
    "    marker_color='blue',\n",
    "    text=train_rmse,  # Add this line to specify the text for each bar\n",
    "    # 'auto' places the text inside the bars; you can also use 'outside' or 'inside'\n",
    "    textposition='auto'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=models,\n",
    "    y=test_rmse,\n",
    "    name='Test RMSE',\n",
    "    marker_color='red',\n",
    "    text=test_rmse,  # Add this line to specify the text for each bar\n",
    "    # 'auto' places the text inside the bars; you can also use 'outside' or 'inside'\n",
    "    textposition='auto'\n",
    "))\n",
    "# Update the layout\n",
    "fig.update_layout(\n",
    "    barmode='group',\n",
    "    title='RMSE',\n",
    "    xaxis_title='Models',\n",
    "    yaxis_title='Value',\n",
    "    legend_title='Data',\n",
    "    width=600,\n",
    "    # plot_bgcolor='rgba(0,0,0,0)',  # Set plot background color to transparent\n",
    "    # paper_bgcolor='rgba(0,0,0,0)'\n",
    ")\n",
    "\n",
    "# # Line chart for std\n",
    "# fig.add_trace(go.Scatter(\n",
    "#     x=models,\n",
    "#     y=[stdev for model in models],\n",
    "#     mode='lines+markers',\n",
    "#     name='Std',\n",
    "#     line=dict(color='green', width=2)\n",
    "# ))\n",
    "\n",
    "# Line chart for std\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=models,\n",
    "    y=[standard_deviation for i in range(len(models))],\n",
    "    mode='lines+markers',\n",
    "    name='Std',\n",
    "    line=dict(color='orange', width=2)\n",
    "))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparams tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from xgboost import XGBRegressor\n",
    "# from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "# from sklearn.metrics import make_scorer, mean_squared_error\n",
    "\n",
    "# # Define your model\n",
    "# xgb = LGBMRegressor(random_state=42)\n",
    "\n",
    "# # Define the parameter grid\n",
    "# param_grid = {\n",
    "#     'num_leaves': [31, 41, 51],  # Increase in steps to see the effect\n",
    "#     'max_depth': [5, 10, 15],  # Adjust based on the complexity of the problem\n",
    "#     'learning_rate': [0.01, 0.05],  # Small steps to see incremental benefits\n",
    "#     'n_estimators': [100, 200],  # More trees can be better, but watch for overfitting\n",
    "#     'subsample': [0.8, 0.9, 1.0],  # Typical subsampling rates\n",
    "#     'min_child_samples': [20, 30, 40]  # Increasing it can combat overfitting\n",
    "# }\n",
    "\n",
    "# # Setup the scoring function\n",
    "# scorer = make_scorer(mean_squared_error, greater_is_better=False, squared=False)\n",
    "\n",
    "# #Setup the GroupKFold\n",
    "# tscv = TimeSeriesSplit(n_splits=3)  # Adjust the number of splits as necessary\n",
    "\n",
    "# # Setup GridSearchCV with GroupKFold\n",
    "# grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid, scoring=scorer, cv=tscv, verbose=2)\n",
    "\n",
    "# # Fit the model using groups\n",
    "# grid_search.fit(X.drop(columns=['month']), y)\n",
    "\n",
    "# # Get the best estimator and its parameters\n",
    "# best_xgb = grid_search.best_estimator_\n",
    "# best_params = grid_search.best_params_\n",
    "\n",
    "# print(\"Best parameters:\", best_params)\n",
    "# print(\"Best RMSE:\", -grid_search.best_score_)  # Note: 'best_score_' is negative, so take the negative of it\n",
    "\n",
    "# # Optionally, use the best model to make predictions or further analysis\n",
    "# # predictions = best_xgb.predict(X_test)\n",
    "# # rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "# # print(\"Test RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | learni... | max_depth | n_esti... | subsample |\n",
      "-------------------------------------------------------------------------------------\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000527 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000660 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002126 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m-15.99   \u001b[0m | \u001b[0m0.6873   \u001b[0m | \u001b[0m0.1906   \u001b[0m | \u001b[0m11.25    \u001b[0m | \u001b[0m109.9    \u001b[0m | \u001b[0m0.578    \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000906 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000432 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000398 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000440 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m-16.8    \u001b[0m | \u001b[0m0.578    \u001b[0m | \u001b[0m0.02104  \u001b[0m | \u001b[0m13.13    \u001b[0m | \u001b[0m110.1    \u001b[0m | \u001b[0m0.854    \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000532 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000393 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000456 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000375 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m-16.0    \u001b[0m | \u001b[0m0.5103   \u001b[0m | \u001b[0m0.1943   \u001b[0m | \u001b[0m12.65    \u001b[0m | \u001b[0m71.23    \u001b[0m | \u001b[0m0.5909   \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000568 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000597 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000596 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000399 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m-16.25   \u001b[0m | \u001b[0m0.5917   \u001b[0m | \u001b[0m0.06781  \u001b[0m | \u001b[0m8.347    \u001b[0m | \u001b[0m93.19    \u001b[0m | \u001b[0m0.6456   \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000533 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000609 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000457 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000489 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m-16.18   \u001b[0m | \u001b[0m0.8059   \u001b[0m | \u001b[0m0.0365   \u001b[0m | \u001b[0m5.09     \u001b[0m | \u001b[0m86.64    \u001b[0m | \u001b[0m0.728    \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000689 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000745 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000517 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000564 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m-16.04   \u001b[0m | \u001b[0m0.8926   \u001b[0m | \u001b[0m0.04794  \u001b[0m | \u001b[0m8.199    \u001b[0m | \u001b[0m109.2    \u001b[0m | \u001b[0m0.5232   \u001b[0m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000697 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000720 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000428 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000552 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m-17.2    \u001b[0m | \u001b[0m0.8038   \u001b[0m | \u001b[0m0.0424   \u001b[0m | \u001b[0m1.911    \u001b[0m | \u001b[0m144.9    \u001b[0m | \u001b[0m0.9828   \u001b[0m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000509 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000690 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000642 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000506 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m-16.62   \u001b[0m | \u001b[0m0.9042   \u001b[0m | \u001b[0m0.06788  \u001b[0m | \u001b[0m2.367    \u001b[0m | \u001b[0m118.4    \u001b[0m | \u001b[0m0.7201   \u001b[0m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000518 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000465 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000590 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000380 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m-17.12   \u001b[0m | \u001b[0m0.561    \u001b[0m | \u001b[0m0.1041   \u001b[0m | \u001b[0m1.481    \u001b[0m | \u001b[0m140.9    \u001b[0m | \u001b[0m0.6294   \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000572 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000628 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000783 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000549 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[95m10       \u001b[0m | \u001b[95m-15.98   \u001b[0m | \u001b[95m0.8313   \u001b[0m | \u001b[95m0.06923  \u001b[0m | \u001b[95m8.281    \u001b[0m | \u001b[95m104.7    \u001b[0m | \u001b[95m0.5924   \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000644 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000712 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000673 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000601 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[95m11       \u001b[0m | \u001b[95m-15.96   \u001b[0m | \u001b[95m0.7039   \u001b[0m | \u001b[95m0.1101   \u001b[0m | \u001b[95m11.36    \u001b[0m | \u001b[95m109.6    \u001b[0m | \u001b[95m0.6463   \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000346 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000645 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000586 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000855 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m-15.96   \u001b[0m | \u001b[0m0.5      \u001b[0m | \u001b[0m0.2      \u001b[0m | \u001b[0m10.29    \u001b[0m | \u001b[0m107.0    \u001b[0m | \u001b[0m0.5      \u001b[0m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000447 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000496 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000689 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000448 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m-17.52   \u001b[0m | \u001b[0m0.5      \u001b[0m | \u001b[0m0.01     \u001b[0m | \u001b[0m4.86     \u001b[0m | \u001b[0m105.7    \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000613 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000465 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000501 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000620 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m-16.62   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.01     \u001b[0m | \u001b[0m10.72    \u001b[0m | \u001b[0m103.6    \u001b[0m | \u001b[0m0.5      \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000518 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000627 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000633 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000567 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m-16.01   \u001b[0m | \u001b[0m0.5382   \u001b[0m | \u001b[0m0.1884   \u001b[0m | \u001b[0m13.07    \u001b[0m | \u001b[0m73.82    \u001b[0m | \u001b[0m0.5812   \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000427 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000668 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000562 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000641 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m-15.96   \u001b[0m | \u001b[0m0.7178   \u001b[0m | \u001b[0m0.1703   \u001b[0m | \u001b[0m10.34    \u001b[0m | \u001b[0m72.9     \u001b[0m | \u001b[0m0.5713   \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000422 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000397 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000536 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000721 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m-17.1    \u001b[0m | \u001b[0m0.7005   \u001b[0m | \u001b[0m0.01     \u001b[0m | \u001b[0m9.651    \u001b[0m | \u001b[0m69.88    \u001b[0m | \u001b[0m0.5      \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000534 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000435 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000513 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000556 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m-15.99   \u001b[0m | \u001b[0m0.5      \u001b[0m | \u001b[0m0.2      \u001b[0m | \u001b[0m10.71    \u001b[0m | \u001b[0m75.2     \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000607 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000516 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002415 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000606 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m-16.95   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.01     \u001b[0m | \u001b[0m15.0     \u001b[0m | \u001b[0m71.71    \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000557 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000676 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000560 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000439 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m-16.58   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.01     \u001b[0m | \u001b[0m9.983    \u001b[0m | \u001b[0m108.7    \u001b[0m | \u001b[0m0.5      \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000387 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000687 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000800 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000406 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m21       \u001b[0m | \u001b[0m-16.01   \u001b[0m | \u001b[0m0.5605   \u001b[0m | \u001b[0m0.1923   \u001b[0m | \u001b[0m11.48    \u001b[0m | \u001b[0m73.8     \u001b[0m | \u001b[0m0.7253   \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000428 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000580 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001601 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000595 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m22       \u001b[0m | \u001b[0m-16.07   \u001b[0m | \u001b[0m0.9355   \u001b[0m | \u001b[0m0.1539   \u001b[0m | \u001b[0m9.129    \u001b[0m | \u001b[0m106.1    \u001b[0m | \u001b[0m0.8681   \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000683 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000466 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000627 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000699 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m23       \u001b[0m | \u001b[0m-16.07   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.2      \u001b[0m | \u001b[0m9.391    \u001b[0m | \u001b[0m74.21    \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000500 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002267 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000620 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000554 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m-16.03   \u001b[0m | \u001b[0m0.9323   \u001b[0m | \u001b[0m0.06258  \u001b[0m | \u001b[0m12.02    \u001b[0m | \u001b[0m72.57    \u001b[0m | \u001b[0m0.9575   \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000607 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000723 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000653 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000787 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m25       \u001b[0m | \u001b[0m-15.97   \u001b[0m | \u001b[0m0.6846   \u001b[0m | \u001b[0m0.07265  \u001b[0m | \u001b[0m12.85    \u001b[0m | \u001b[0m75.81    \u001b[0m | \u001b[0m0.7823   \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000373 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000634 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000607 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000628 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m26       \u001b[0m | \u001b[0m-15.98   \u001b[0m | \u001b[0m0.5209   \u001b[0m | \u001b[0m0.2      \u001b[0m | \u001b[0m7.006    \u001b[0m | \u001b[0m110.8    \u001b[0m | \u001b[0m0.5492   \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000395 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000396 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000676 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000572 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m27       \u001b[0m | \u001b[0m-17.34   \u001b[0m | \u001b[0m0.5      \u001b[0m | \u001b[0m0.01     \u001b[0m | \u001b[0m8.826    \u001b[0m | \u001b[0m111.7    \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000413 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000475 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000601 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000497 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m28       \u001b[0m | \u001b[0m-16.07   \u001b[0m | \u001b[0m0.9297   \u001b[0m | \u001b[0m0.137    \u001b[0m | \u001b[0m6.5      \u001b[0m | \u001b[0m109.4    \u001b[0m | \u001b[0m0.7771   \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000384 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001978 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000451 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001851 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m29       \u001b[0m | \u001b[0m-16.07   \u001b[0m | \u001b[0m0.8896   \u001b[0m | \u001b[0m0.135    \u001b[0m | \u001b[0m5.442    \u001b[0m | \u001b[0m111.2    \u001b[0m | \u001b[0m0.5384   \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000537 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000553 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000535 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000434 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m30       \u001b[0m | \u001b[0m-16.08   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.2      \u001b[0m | \u001b[0m11.33    \u001b[0m | \u001b[0m77.16    \u001b[0m | \u001b[0m0.5      \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000403 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000565 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000606 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000399 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m31       \u001b[0m | \u001b[0m-16.06   \u001b[0m | \u001b[0m0.6191   \u001b[0m | \u001b[0m0.1065   \u001b[0m | \u001b[0m11.91    \u001b[0m | \u001b[0m106.5    \u001b[0m | \u001b[0m0.9619   \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000388 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000885 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005215 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000832 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m32       \u001b[0m | \u001b[0m-16.22   \u001b[0m | \u001b[0m0.6496   \u001b[0m | \u001b[0m0.02624  \u001b[0m | \u001b[0m13.73    \u001b[0m | \u001b[0m77.75    \u001b[0m | \u001b[0m0.9765   \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000579 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000450 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000365 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002123 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m33       \u001b[0m | \u001b[0m-17.63   \u001b[0m | \u001b[0m0.5      \u001b[0m | \u001b[0m0.01     \u001b[0m | \u001b[0m8.946    \u001b[0m | \u001b[0m76.66    \u001b[0m | \u001b[0m0.5      \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000319 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007255 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000732 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000495 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m34       \u001b[0m | \u001b[0m-16.23   \u001b[0m | \u001b[0m0.5924   \u001b[0m | \u001b[0m0.08613  \u001b[0m | \u001b[0m14.75    \u001b[0m | \u001b[0m75.24    \u001b[0m | \u001b[0m0.5255   \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000578 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000589 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000499 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000610 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m35       \u001b[0m | \u001b[0m-15.97   \u001b[0m | \u001b[0m0.6617   \u001b[0m | \u001b[0m0.156    \u001b[0m | \u001b[0m7.695    \u001b[0m | \u001b[0m102.4    \u001b[0m | \u001b[0m0.7055   \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000360 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000647 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000569 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000684 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m36       \u001b[0m | \u001b[0m-16.11   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.2      \u001b[0m | \u001b[0m7.06     \u001b[0m | \u001b[0m100.5    \u001b[0m | \u001b[0m0.5      \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000382 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000698 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000541 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000732 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m37       \u001b[0m | \u001b[0m-16.28   \u001b[0m | \u001b[0m0.5306   \u001b[0m | \u001b[0m0.05935  \u001b[0m | \u001b[0m9.035    \u001b[0m | \u001b[0m100.3    \u001b[0m | \u001b[0m0.8452   \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000286 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000613 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000420 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000598 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m38       \u001b[0m | \u001b[0m-15.99   \u001b[0m | \u001b[0m0.6448   \u001b[0m | \u001b[0m0.168    \u001b[0m | \u001b[0m5.418    \u001b[0m | \u001b[0m101.7    \u001b[0m | \u001b[0m0.7736   \u001b[0m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000350 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000714 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000676 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000594 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m39       \u001b[0m | \u001b[0m-16.15   \u001b[0m | \u001b[0m0.9142   \u001b[0m | \u001b[0m0.06483  \u001b[0m | \u001b[0m4.659    \u001b[0m | \u001b[0m99.8     \u001b[0m | \u001b[0m0.7276   \u001b[0m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000430 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000654 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000617 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000677 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m40       \u001b[0m | \u001b[0m-16.12   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.2      \u001b[0m | \u001b[0m3.157    \u001b[0m | \u001b[0m101.5    \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000485 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000563 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000728 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000712 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "| \u001b[0m41       \u001b[0m | \u001b[0m-16.38   \u001b[0m | \u001b[0m0.8559   \u001b[0m | \u001b[0m0.1517   \u001b[0m | \u001b[0m2.006    \u001b[0m | \u001b[0m99.23    \u001b[0m | \u001b[0m0.5387   \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000650 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000766 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000696 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000787 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m42       \u001b[0m | \u001b[0m-16.06   \u001b[0m | \u001b[0m0.9123   \u001b[0m | \u001b[0m0.1414   \u001b[0m | \u001b[0m12.12    \u001b[0m | \u001b[0m79.54    \u001b[0m | \u001b[0m0.6498   \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000595 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000764 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000685 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m43       \u001b[0m | \u001b[0m-15.99   \u001b[0m | \u001b[0m0.6477   \u001b[0m | \u001b[0m0.0797   \u001b[0m | \u001b[0m13.39    \u001b[0m | \u001b[0m81.38    \u001b[0m | \u001b[0m0.7366   \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000456 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000586 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000568 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000560 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m44       \u001b[0m | \u001b[0m-16.09   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.2      \u001b[0m | \u001b[0m11.48    \u001b[0m | \u001b[0m81.76    \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000511 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000558 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000585 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000438 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m45       \u001b[0m | \u001b[0m-16.13   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.2      \u001b[0m | \u001b[0m13.21    \u001b[0m | \u001b[0m83.41    \u001b[0m | \u001b[0m0.5      \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000441 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000480 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000847 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002226 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m46       \u001b[0m | \u001b[0m-16.01   \u001b[0m | \u001b[0m0.93     \u001b[0m | \u001b[0m0.0767   \u001b[0m | \u001b[0m14.66    \u001b[0m | \u001b[0m80.05    \u001b[0m | \u001b[0m0.9057   \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000386 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000384 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000809 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000685 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m47       \u001b[0m | \u001b[0m-16.7    \u001b[0m | \u001b[0m0.6056   \u001b[0m | \u001b[0m0.03447  \u001b[0m | \u001b[0m14.95    \u001b[0m | \u001b[0m82.46    \u001b[0m | \u001b[0m0.942    \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000445 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000563 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000707 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000551 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m48       \u001b[0m | \u001b[0m-16.05   \u001b[0m | \u001b[0m0.8891   \u001b[0m | \u001b[0m0.146    \u001b[0m | \u001b[0m11.18    \u001b[0m | \u001b[0m84.39    \u001b[0m | \u001b[0m0.6942   \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000297 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000489 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000485 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000556 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m49       \u001b[0m | \u001b[0m-16.1    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.2      \u001b[0m | \u001b[0m12.67    \u001b[0m | \u001b[0m85.94    \u001b[0m | \u001b[0m0.5      \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000547 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003330 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000947 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000741 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m50       \u001b[0m | \u001b[0m-16.03   \u001b[0m | \u001b[0m0.8763   \u001b[0m | \u001b[0m0.06296  \u001b[0m | \u001b[0m10.33    \u001b[0m | \u001b[0m86.64    \u001b[0m | \u001b[0m0.8122   \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000505 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000762 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000557 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000559 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m51       \u001b[0m | \u001b[0m-16.32   \u001b[0m | \u001b[0m0.6216   \u001b[0m | \u001b[0m0.06329  \u001b[0m | \u001b[0m8.987    \u001b[0m | \u001b[0m84.75    \u001b[0m | \u001b[0m0.8253   \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000410 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000557 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000612 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000660 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m52       \u001b[0m | \u001b[0m-16.07   \u001b[0m | \u001b[0m0.9389   \u001b[0m | \u001b[0m0.1649   \u001b[0m | \u001b[0m11.68    \u001b[0m | \u001b[0m88.16    \u001b[0m | \u001b[0m0.6891   \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000484 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000539 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000615 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000627 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m53       \u001b[0m | \u001b[0m-16.1    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.2      \u001b[0m | \u001b[0m9.413    \u001b[0m | \u001b[0m88.63    \u001b[0m | \u001b[0m0.5      \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000383 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000402 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000563 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000586 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m54       \u001b[0m | \u001b[0m-17.53   \u001b[0m | \u001b[0m0.5      \u001b[0m | \u001b[0m0.01     \u001b[0m | \u001b[0m10.93    \u001b[0m | \u001b[0m90.42    \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000478 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000646 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000756 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000560 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m55       \u001b[0m | \u001b[0m-16.1    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.2      \u001b[0m | \u001b[0m7.826    \u001b[0m | \u001b[0m87.42    \u001b[0m | \u001b[0m0.5      \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000619 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000678 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000675 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001455 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m56       \u001b[0m | \u001b[0m-16.1    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.2      \u001b[0m | \u001b[0m6.484    \u001b[0m | \u001b[0m89.34    \u001b[0m | \u001b[0m0.5      \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000579 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000717 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000525 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000542 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m57       \u001b[0m | \u001b[0m-15.97   \u001b[0m | \u001b[0m0.7434   \u001b[0m | \u001b[0m0.1211   \u001b[0m | \u001b[0m14.24    \u001b[0m | \u001b[0m87.93    \u001b[0m | \u001b[0m0.5568   \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000669 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000553 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000714 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000715 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m58       \u001b[0m | \u001b[0m-15.98   \u001b[0m | \u001b[0m0.8482   \u001b[0m | \u001b[0m0.1553   \u001b[0m | \u001b[0m14.93    \u001b[0m | \u001b[0m86.44    \u001b[0m | \u001b[0m0.5382   \u001b[0m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000496 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000772 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000666 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m59       \u001b[0m | \u001b[0m-17.64   \u001b[0m | \u001b[0m0.5      \u001b[0m | \u001b[0m0.01     \u001b[0m | \u001b[0m4.034    \u001b[0m | \u001b[0m89.33    \u001b[0m | \u001b[0m0.5      \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000631 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000707 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000467 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000520 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m60       \u001b[0m | \u001b[0m-16.07   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.2      \u001b[0m | \u001b[0m5.052    \u001b[0m | \u001b[0m84.15    \u001b[0m | \u001b[0m0.9722   \u001b[0m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000652 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000632 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000552 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000450 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "| \u001b[0m61       \u001b[0m | \u001b[0m-16.6    \u001b[0m | \u001b[0m0.5279   \u001b[0m | \u001b[0m0.1358   \u001b[0m | \u001b[0m2.762    \u001b[0m | \u001b[0m84.41    \u001b[0m | \u001b[0m0.5862   \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000577 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000697 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000500 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000688 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m62       \u001b[0m | \u001b[0m-15.99   \u001b[0m | \u001b[0m0.7277   \u001b[0m | \u001b[0m0.1999   \u001b[0m | \u001b[0m6.547    \u001b[0m | \u001b[0m82.43    \u001b[0m | \u001b[0m0.9518   \u001b[0m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000537 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000684 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000628 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000496 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m63       \u001b[0m | \u001b[0m-16.04   \u001b[0m | \u001b[0m0.8499   \u001b[0m | \u001b[0m0.1929   \u001b[0m | \u001b[0m4.894    \u001b[0m | \u001b[0m81.69    \u001b[0m | \u001b[0m0.9189   \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000648 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000697 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000449 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000630 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m64       \u001b[0m | \u001b[0m-16.3    \u001b[0m | \u001b[0m0.8902   \u001b[0m | \u001b[0m0.0226   \u001b[0m | \u001b[0m6.317    \u001b[0m | \u001b[0m80.24    \u001b[0m | \u001b[0m0.6304   \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000545 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000601 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000500 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000459 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m65       \u001b[0m | \u001b[0m-16.01   \u001b[0m | \u001b[0m0.6555   \u001b[0m | \u001b[0m0.07851  \u001b[0m | \u001b[0m6.714    \u001b[0m | \u001b[0m85.03    \u001b[0m | \u001b[0m0.5081   \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000428 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000534 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000641 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000497 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m66       \u001b[0m | \u001b[0m-16.14   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.2      \u001b[0m | \u001b[0m15.0     \u001b[0m | \u001b[0m89.86    \u001b[0m | \u001b[0m0.5      \u001b[0m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000518 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000527 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000704 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000506 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m67       \u001b[0m | \u001b[0m-16.17   \u001b[0m | \u001b[0m0.6427   \u001b[0m | \u001b[0m0.1452   \u001b[0m | \u001b[0m3.001    \u001b[0m | \u001b[0m80.03    \u001b[0m | \u001b[0m0.7152   \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000304 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000627 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000620 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000480 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m68       \u001b[0m | \u001b[0m-16.01   \u001b[0m | \u001b[0m0.5174   \u001b[0m | \u001b[0m0.1872   \u001b[0m | \u001b[0m8.859    \u001b[0m | \u001b[0m82.18    \u001b[0m | \u001b[0m0.6465   \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000473 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000505 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000595 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000605 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m69       \u001b[0m | \u001b[0m-16.0    \u001b[0m | \u001b[0m0.5      \u001b[0m | \u001b[0m0.2      \u001b[0m | \u001b[0m6.606    \u001b[0m | \u001b[0m97.4     \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000471 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000419 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000640 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000554 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m70       \u001b[0m | \u001b[0m-16.08   \u001b[0m | \u001b[0m0.9055   \u001b[0m | \u001b[0m0.1711   \u001b[0m | \u001b[0m6.143    \u001b[0m | \u001b[0m95.42    \u001b[0m | \u001b[0m0.8406   \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000379 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000386 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000697 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000339 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m71       \u001b[0m | \u001b[0m-16.7    \u001b[0m | \u001b[0m0.5743   \u001b[0m | \u001b[0m0.02963  \u001b[0m | \u001b[0m8.458    \u001b[0m | \u001b[0m96.37    \u001b[0m | \u001b[0m0.6814   \u001b[0m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000502 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000691 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000661 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010915 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m72       \u001b[0m | \u001b[0m-16.04   \u001b[0m | \u001b[0m0.6971   \u001b[0m | \u001b[0m0.1641   \u001b[0m | \u001b[0m4.514    \u001b[0m | \u001b[0m96.96    \u001b[0m | \u001b[0m0.6672   \u001b[0m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000326 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000658 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000572 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000469 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "| \u001b[0m73       \u001b[0m | \u001b[0m-16.27   \u001b[0m | \u001b[0m0.8614   \u001b[0m | \u001b[0m0.08006  \u001b[0m | \u001b[0m3.651    \u001b[0m | \u001b[0m95.0     \u001b[0m | \u001b[0m0.6828   \u001b[0m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000626 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000541 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000706 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000636 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "| \u001b[0m74       \u001b[0m | \u001b[0m-16.46   \u001b[0m | \u001b[0m0.7148   \u001b[0m | \u001b[0m0.116    \u001b[0m | \u001b[0m2.684    \u001b[0m | \u001b[0m112.0    \u001b[0m | \u001b[0m0.9899   \u001b[0m |\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000694 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000947 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000832 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000650 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "| \u001b[0m75       \u001b[0m | \u001b[0m-17.19   \u001b[0m | \u001b[0m0.8285   \u001b[0m | \u001b[0m0.0819   \u001b[0m | \u001b[0m1.038    \u001b[0m | \u001b[0m77.66    \u001b[0m | \u001b[0m0.8577   \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000627 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000667 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002911 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003307 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m76       \u001b[0m | \u001b[0m-15.96   \u001b[0m | \u001b[0m0.7046   \u001b[0m | \u001b[0m0.1887   \u001b[0m | \u001b[0m14.8     \u001b[0m | \u001b[0m105.6    \u001b[0m | \u001b[0m0.8671   \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000695 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000605 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000491 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000748 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m77       \u001b[0m | \u001b[0m-16.04   \u001b[0m | \u001b[0m0.8963   \u001b[0m | \u001b[0m0.1072   \u001b[0m | \u001b[0m14.84    \u001b[0m | \u001b[0m103.6    \u001b[0m | \u001b[0m0.5388   \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000694 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000753 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000739 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000699 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m78       \u001b[0m | \u001b[0m-15.97   \u001b[0m | \u001b[0m0.5      \u001b[0m | \u001b[0m0.2      \u001b[0m | \u001b[0m15.0     \u001b[0m | \u001b[0m101.2    \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000441 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000454 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000495 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000527 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m79       \u001b[0m | \u001b[0m-16.65   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m0.01     \u001b[0m | \u001b[0m15.0     \u001b[0m | \u001b[0m99.26    \u001b[0m | \u001b[0m0.5      \u001b[0m |\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000429 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.063451\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000880 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 4.500640\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000670 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.133923\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000509 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 301\n",
      "[LightGBM] [Info] Number of data points in the train set: 58482, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 5.308049\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "| \u001b[0m80       \u001b[0m | \u001b[0m-15.96   \u001b[0m | \u001b[0m0.6319   \u001b[0m | \u001b[0m0.09304  \u001b[0m | \u001b[0m13.61    \u001b[0m | \u001b[0m102.3    \u001b[0m | \u001b[0m0.8149   \u001b[0m |\n",
      "=====================================================================================\n",
      "Best parameters: {'colsample_bytree': 0.7038755684949335, 'learning_rate': 0.11013793300385055, 'max_depth': 11.364143630698788, 'n_estimators': 109.5960634511761, 'subsample': 0.6462814449296451}\n"
     ]
    }
   ],
   "source": [
    "# from bayes_opt import BayesianOptimization\n",
    "# from lightgbm import LGBMRegressor\n",
    "# from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "# import numpy as np\n",
    "\n",
    "# # Assume 'X' and 'y' are your feature matrix and target variable\n",
    "# kf = KFold(n_splits=4)\n",
    "\n",
    "# # Define your LGBM training function\n",
    "# def LGBM_evaluate(max_depth, n_estimators, learning_rate, colsample_bytree, subsample):\n",
    "#     params = {\n",
    "#         'max_depth': int(max_depth),\n",
    "#         'n_estimators': int(n_estimators),\n",
    "#         'learning_rate': learning_rate,\n",
    "#         'colsample_bytree': colsample_bytree,\n",
    "#         'subsample': subsample,\n",
    "#         'random_state': 42\n",
    "#     }\n",
    "#     lgbm = LGBMRegressor(**params)\n",
    "#     # Ensure that X is prepared without needing to drop columns as in your example\n",
    "#     cv_scores = cross_val_score(lgbm, X, y, cv=kf, scoring='neg_root_mean_squared_error')\n",
    "#     return np.mean(cv_scores)\n",
    "\n",
    "# # Set up Bayesian Optimization\n",
    "# optimizer = BayesianOptimization(\n",
    "#     f=LGBM_evaluate,\n",
    "#     pbounds={\n",
    "#         'max_depth': (1, 15),\n",
    "#         'n_estimators': (50, 150),\n",
    "#         'learning_rate': (0.01, 0.2),\n",
    "#         'colsample_bytree': (0.5, 1.0),\n",
    "#         'subsample': (0.5, 1.0)\n",
    "#     },\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "# # Run optimization\n",
    "# optimizer.maximize(init_points=10, n_iter=70)\n",
    "\n",
    "# # Print best parameters\n",
    "# print(\"Best parameters:\", optimizer.max['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bayes_opt import BayesianOptimization\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "# import numpy as np\n",
    "\n",
    "# # Assume 'y' is your target variable\n",
    "# tscv = TimeSeriesSplit(n_splits=3) \n",
    "# # Define your RandomForest training function\n",
    "# def RF_evaluate(max_depth, n_estimators, min_samples_split, min_samples_leaf):\n",
    "#     params = {\n",
    "#         'max_depth': int(max_depth),\n",
    "#         'n_estimators': int(n_estimators),\n",
    "#         'min_samples_split': int(min_samples_split),\n",
    "#         'min_samples_leaf': int(min_samples_leaf),\n",
    "#         'random_state': 42\n",
    "#     }\n",
    "#     rf = RandomForestRegressor(**params)\n",
    "#     cv_scores = cross_val_score(rf, X.drop(columns=['month']), y, cv=tscv, scoring='neg_root_mean_squared_error')\n",
    "#     return np.mean(cv_scores)\n",
    "\n",
    "# # Set up Bayesian Optimization\n",
    "# optimizer = BayesianOptimization(\n",
    "#     f=RF_evaluate,\n",
    "#     pbounds={\n",
    "#         'max_depth': (1, 15),\n",
    "#         'n_estimators': (50, 150),\n",
    "#         'min_samples_split': (2, 10),\n",
    "#         'min_samples_leaf': (1, 4)\n",
    "#     },\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "# # Run optimization\n",
    "# optimizer.maximize(init_points=10, n_iter=70)\n",
    "\n",
    "# # Print best parameters\n",
    "# print(\"Best parameters:\", optimizer.max['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_xgb = {'colsample_bytree': 0.8, 'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 300, 'subsample': 0.8}\n",
    "best_params_rf = {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 150}\n",
    "# Create Extra Trees model using the best parameters\n",
    "# best_model = XGBRegressor(**best_params_xgb, random_state=42)\n",
    "# best_model = RandomForestRegressor(**best_params_rf, random_state=42)\n",
    "best_model = LGBMRegressor(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>precip_est</th>\n",
       "      <th>bias_oct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>38.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>1981</td>\n",
       "      <td>11</td>\n",
       "      <td>64.224060</td>\n",
       "      <td>-22.354310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>38.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>1981</td>\n",
       "      <td>11</td>\n",
       "      <td>59.290470</td>\n",
       "      <td>-34.947810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>38.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>1981</td>\n",
       "      <td>11</td>\n",
       "      <td>55.923283</td>\n",
       "      <td>-31.967342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>38.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>1981</td>\n",
       "      <td>11</td>\n",
       "      <td>52.946720</td>\n",
       "      <td>-37.812560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>38.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>1981</td>\n",
       "      <td>11</td>\n",
       "      <td>48.997500</td>\n",
       "      <td>-51.481626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230231</th>\n",
       "      <td>20.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>0.391094</td>\n",
       "      <td>-0.524434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230232</th>\n",
       "      <td>20.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>0.723125</td>\n",
       "      <td>-0.879048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230233</th>\n",
       "      <td>20.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>0.824687</td>\n",
       "      <td>-1.292470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230234</th>\n",
       "      <td>20.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>0.445781</td>\n",
       "      <td>-2.873006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230235</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>0.152812</td>\n",
       "      <td>-1.964345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77976 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         lat   lon  year  month  precip_est   bias_oct\n",
       "289     38.0 -18.0  1981     11   64.224060 -22.354310\n",
       "290     38.0 -17.0  1981     11   59.290470 -34.947810\n",
       "291     38.0 -16.0  1981     11   55.923283 -31.967342\n",
       "292     38.0 -15.0  1981     11   52.946720 -37.812560\n",
       "293     38.0 -14.0  1981     11   48.997500 -51.481626\n",
       "...      ...   ...   ...    ...         ...        ...\n",
       "230231  20.0  -4.0  2017      4    0.391094  -0.524434\n",
       "230232  20.0  -3.0  2017      4    0.723125  -0.879048\n",
       "230233  20.0  -2.0  2017      4    0.824687  -1.292470\n",
       "230234  20.0  -1.0  2017      4    0.445781  -2.873006\n",
       "230235  20.0   0.0  2017      4    0.152812  -1.964345\n",
       "\n",
       "[77976 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oct_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000740 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 294\n",
      "[LightGBM] [Info] Number of data points in the train set: 62380, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 3.008781\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.drop(columns=['year', 'month']), y, test_size=0.2, random_state=42)\n",
    "\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lat', 'lon', 'year', 'month', 'precip_est', 'bias_oct'], dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oct_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "oct_final = pd.DataFrame({\n",
    "    'bias_test': y_test,\n",
    "    'bias_pred': y_pred,\n",
    "    'lat': X_test['lat'],\n",
    "    'lon': X_test['lon'],\n",
    "    'month': oct_test.loc[X_test.index, 'month'],  # Extract 'month' from the original DataFrame using the indices of X_test\n",
    "    'prec_est': X_test['precip_est'],\n",
    "    'corrected_prec': X_test['precip_est'] - y_pred\n",
    "})\n",
    "\n",
    "# Reset index of the oct_final DataFrame if needed for clean output\n",
    "oct_final.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias_test</th>\n",
       "      <th>bias_pred</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>month</th>\n",
       "      <th>prec_est</th>\n",
       "      <th>corrected_prec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.369538</td>\n",
       "      <td>-0.670557</td>\n",
       "      <td>26.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.369538</td>\n",
       "      <td>1.040095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.994721</td>\n",
       "      <td>-0.008064</td>\n",
       "      <td>26.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.994721</td>\n",
       "      <td>2.002785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.850997</td>\n",
       "      <td>-2.435933</td>\n",
       "      <td>37.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>51.297256</td>\n",
       "      <td>53.733189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-27.132019</td>\n",
       "      <td>-35.903321</td>\n",
       "      <td>34.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>11</td>\n",
       "      <td>16.439453</td>\n",
       "      <td>52.342774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.157362</td>\n",
       "      <td>-0.222417</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>12</td>\n",
       "      <td>3.164442</td>\n",
       "      <td>3.386859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15591</th>\n",
       "      <td>-11.645460</td>\n",
       "      <td>11.658641</td>\n",
       "      <td>36.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>12</td>\n",
       "      <td>113.644460</td>\n",
       "      <td>101.985819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15592</th>\n",
       "      <td>-8.797730</td>\n",
       "      <td>-25.850255</td>\n",
       "      <td>34.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>33.659850</td>\n",
       "      <td>59.510105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15593</th>\n",
       "      <td>24.589799</td>\n",
       "      <td>12.463901</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>12</td>\n",
       "      <td>32.955430</td>\n",
       "      <td>20.491529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15594</th>\n",
       "      <td>38.462360</td>\n",
       "      <td>27.727757</td>\n",
       "      <td>37.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>12</td>\n",
       "      <td>81.156450</td>\n",
       "      <td>53.428693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15595</th>\n",
       "      <td>2.862677</td>\n",
       "      <td>0.572157</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.984747</td>\n",
       "      <td>2.412590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15596 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       bias_test  bias_pred   lat   lon  month    prec_est  corrected_prec\n",
       "0       0.369538  -0.670557  26.0  -1.0      1    0.369538        1.040095\n",
       "1       1.994721  -0.008064  26.0  -7.0      1    1.994721        2.002785\n",
       "2      36.850997  -2.435933  37.0  -7.0      2   51.297256       53.733189\n",
       "3     -27.132019 -35.903321  34.0  -4.0     11   16.439453       52.342774\n",
       "4       2.157362  -0.222417  28.0 -10.0     12    3.164442        3.386859\n",
       "...          ...        ...   ...   ...    ...         ...             ...\n",
       "15591 -11.645460  11.658641  36.0  -6.0     12  113.644460      101.985819\n",
       "15592  -8.797730 -25.850255  34.0  -4.0      3   33.659850       59.510105\n",
       "15593  24.589799  12.463901  30.0 -15.0     12   32.955430       20.491529\n",
       "15594  38.462360  27.727757  37.0  -7.0     12   81.156450       53.428693\n",
       "15595   2.862677   0.572157  24.0 -14.0      3    2.984747        2.412590\n",
       "\n",
       "[15596 rows x 7 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oct_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DataScience\\AppData\\Local\\Temp\\ipykernel_32856\\200919702.py:6: DeprecationWarning:\n",
      "\n",
      "DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_rmse(group):\n",
    "    return np.sqrt(mean_squared_error(group['bias_test'], group['bias_pred']))\n",
    "\n",
    "oct_rmse_ml = oct_final.groupby('month').apply(calculate_rmse).reset_index(name='RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>24.690320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>18.647848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>16.647167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>16.447901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>33.587588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>25.822493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   month       RMSE\n",
       "0      1  24.690320\n",
       "1      2  18.647848\n",
       "2      3  16.647167\n",
       "3      4  16.447901\n",
       "4     11  33.587588\n",
       "5     12  25.822493"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oct_rmse_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "oct_rmse_ml.to_csv('../DATASET/dataset_test2023/oct_rmse_ml.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "## testing set\n",
    "oct_sub = pd.read_csv ('../DATASET/dataset_test2023/oct23.csv')\n",
    "X_sub = oct_sub[['lat', 'lon', 'prec_est']]\n",
    "\n",
    "y_sub = best_model.predict(X_sub)\n",
    "# oct_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_oct = pd.DataFrame({ # Example: creating a sequence of IDs from 1 to 781\n",
    "    'bias': y_sub,\n",
    "    'lat': oct_sub['lat'],\n",
    "    'lon': oct_sub['lon'],\n",
    "    'month': oct_sub['month'],\n",
    "    'prec_est': oct_sub['prec_est'],\n",
    "    'corrected_prec': oct_sub['prec_est'] - y_sub\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bias              285\n",
       "lat               285\n",
       "lon               285\n",
       "month             285\n",
       "prec_est          285\n",
       "corrected_prec    285\n",
       "dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_oct[submission_oct['corrected_prec'] < 0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_oct.loc[submission_oct['corrected_prec'] < 0, 'corrected_prec'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bias              0\n",
       "lat               0\n",
       "lon               0\n",
       "month             0\n",
       "prec_est          0\n",
       "corrected_prec    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_oct[submission_oct['corrected_prec'] < 0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import TimeSeriesSplit\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# import numpy as np\n",
    "\n",
    "# final_results = {}\n",
    "\n",
    "# # Define the number of splits\n",
    "# tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# # You can iterate over the splits\n",
    "# for train_index, test_index in tscv.split(X):\n",
    "#     # Use .iloc for positional indexing\n",
    "#     x_train_fold, x_test_fold = X.iloc[train_index].drop(columns=['month']), X.iloc[test_index].drop(columns=['month'])\n",
    "#     y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "#     best_model.fit(x_train_fold, y_train_fold)\n",
    "#     y_pred_train = best_model.predict(x_train_fold)\n",
    "#     y_pred_test = best_model.predict(x_test_fold)\n",
    "\n",
    "#     rmse_train = mean_squared_error(\n",
    "#         y_train_fold, y_pred_train, squared=False)\n",
    "#     rmse_test = mean_squared_error(y_test_fold, y_pred_test, squared=False)\n",
    "\n",
    "#     train_rmse_scores.append(rmse_train)\n",
    "#     test_rmse_scores.append(rmse_test)\n",
    "\n",
    "# avg_train_rmse = sum(train_rmse_scores) / k\n",
    "# avg_test_rmse = sum(test_rmse_scores) / k\n",
    "\n",
    "# final_results[\"metrics\"] = {\n",
    "#     \"RMSE train\": avg_train_rmse,\n",
    "#     \"RMSE test\": avg_test_rmse,\n",
    "# }\n",
    "# print(final_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rmse = np.sqrt(mean_squared_error(test['bias_dec'], y_sub))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
